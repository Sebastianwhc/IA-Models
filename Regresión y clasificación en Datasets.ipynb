{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Descripción de la actividad**\n",
        "\n",
        "*   En esta última actividad, aplicará las técnicas de regresión y clasificación en conjuntos de datos.\n",
        "*   Para poder hacer esto, deberá buscar dos datasets diferentes (debidamente referenciados), uno lo utilizará para realizar regresión, el otro lo utilizará para hacer clasificación.\n",
        "*   Adicionalmente, deberá buscar una técnica de regresión y clasificación diferentes a las vistas en clase y utilizados en el Taller 4.\n",
        "*   Se recomienda hacer todo el análisis de datos previo que hemos trabajado para poder tener datos limpios y completos que le permitirán hacer regresión y clasificación.\n",
        "\n"
      ],
      "metadata": {
        "id": "yD70A-i4_BZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Técnica de Clasificación: *Regresión Logistica:*\n"
      ],
      "metadata": {
        "id": "CPFE9bbK_a_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#Para cargar el Dataset desde el drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/train.csv'\n",
        "bmt_train = pd.read_csv(file_path)\n",
        "drive.mount('/content/drive')\n",
        "file_path2 = '/content/drive/MyDrive/test.csv'\n",
        "bmt_test = pd.read_csv(file_path2)\n",
        "\n",
        "# Atributos que no aportan información significativa para resolver el problema objetivo (sí existen).\n",
        "bmt_train = bmt_train.drop([\"contact\", \"month\", \"day\", \"duration\"], axis=1)\n",
        "bmt_train.head()\n",
        "# Identificar la variable objetivo y establecerla como la columna 'y'\n",
        "y = bmt_train['y']\n",
        "X = bmt_train.drop(['y'], axis=1)\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Seleccionar las características numéricas y categóricas para aplicar diferentes transformaciones\n",
        "numeric_cols = X_train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
        "categorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "# Crear una transformación para las características numéricas\n",
        "numeric_transformer = make_pipeline(StandardScaler())\n",
        "\n",
        "# Crear una transformación para las características categóricas\n",
        "categorical_transformer = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "\n",
        "# Combinar las transformaciones numéricas y categóricas en un solo transformador de columnas\n",
        "preprocessor = make_column_transformer((numeric_transformer, numeric_cols),\n",
        "                                       (categorical_transformer, categorical_cols))\n",
        "\n",
        "# Crear el modelo de regresión logística\n",
        "model = make_pipeline(preprocessor, LogisticRegression())\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar el modelo con el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Visualizar la matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eYVbLfx56okX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusión\n",
        "Basándonos en la matriz de confusión y el informe de clasificación, podemos decir que el modelo ha obtenido un rendimiento aceptable en términos de precisión (accuracy) y F1-score, ambos alrededor del 90%.\n",
        "\n",
        "En cuanto a la matriz de confusión, podemos ver que el modelo clasificó correctamente el 89% de los clientes que no suscribieron un depósito a plazo, y el 71% de los clientes que sí lo hicieron. Sin embargo, también cometió algunos errores en la clasificación, como falsos positivos (clientes que no suscribieron un depósito, pero fueron clasificados como si lo hubieran hecho) y falsos negativos (clientes que suscribieron un depósito, pero fueron clasificados como si no lo hubieran hecho).\n",
        "\n",
        "En general, podemos decir que el modelo es útil para predecir si un cliente suscribirá un depósito a plazo o no, pero podría mejorarse aún más con una mayor selección de características y una optimización más cuidadosa de los parámetros del modelo."
      ],
      "metadata": {
        "id": "RIemGNAAvN2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Técnica de Regresión: *Regresión Lineal* (Modelo visto en clase de IA)"
      ],
      "metadata": {
        "id": "RJHgcjMh__Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Cargar el conjunto de datos Palmer Penguins\n",
        "penguins = sns.load_dataset('penguins')\n",
        "\n",
        "# Eliminar las filas con valores faltantes\n",
        "penguins.dropna(inplace=True)\n",
        "\n",
        "# Seleccionar las características y el valor objetivo\n",
        "X = penguins[['bill_length_mm', 'body_mass_g']]\n",
        "y = penguins['flipper_length_mm']\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear el modelo de regresión lineal\n",
        "model = LinearRegression()\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calcular el error cuadrático medio\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Error cuadrático medio: {mse}\")\n",
        "\n",
        "# Imprimir los coeficientes y el intercepto\n",
        "print(f\"Coeficientes: {model.coef_}\")\n",
        "print(f\"Intercepto: {model.intercept_}\")\n"
      ],
      "metadata": {
        "id": "372-sRZ_ABiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb3820b-22de-4ec9-a15e-b0a3dd16ef48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error cuadrático medio: 42.076084373504045\n",
            "Coeficientes: [0.60314056 0.01252866]\n",
            "Intercepto: 121.594446852563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejemplo se va utilizar el modelo de regresión lineal en el conjunto de datos \"Palmer Penguins\" para predecir la longitud de la aleta de los pingüinos en función de la longitud del pico y la masa corporal.\n",
        "\n",
        "*   Error cuadrático medio: El valor del error cuadrático medio obtenido es de 42.076, lo cual indica que el modelo tiene una discrepancia promedio de aproximadamente 42 unidades al predecir la longitud de la aleta de los pingüinos.\n",
        "*   Coeficientes: Los coeficientes del modelo son 0.603 para la longitud del pico y 0.013 para la masa corporal. Estos coeficientes indican que, en promedio, un aumento de una unidad en la longitud del pico está asociado con un aumento de aproximadamente 0.603 unidades en la longitud de la aleta, mientras que un aumento de una unidad en la masa corporal está asociado con un aumento de aproximadamente 0.013 unidades en la longitud de la aleta. Esto sugiere que la longitud del pico tiene una influencia más significativa en la longitud de la aleta en comparación con la masa corporal\n",
        "\n",
        "*   Intercepto: El valor del intercepto del modelo es 121.594. Esto significa que cuando tanto la longitud del pico como la masa corporal son cero, se espera que la longitud de la aleta sea aproximadamente 121.594 unidades.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xipscYKUxHSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owyZbsX9wu65"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}